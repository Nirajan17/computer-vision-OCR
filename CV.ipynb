{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesseract learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO. Item No Description Hscode P/O# S/O# Q'ty(Pcs) Unit Price(USD) Amount(USD)\n",
      "2 104-10001 NeoNatalie Basic (dark) 902300 | TN200259 | S0125175 20 124.00 2480.00\n",
      "10 340-00333 MamaNatalie Compl Light 902300 | TN200259 | S0125175 10 450.00 4500.00\n",
      "1 340-00533 MamaN Compl (LT) Mama-U 902300 | TN200259 | SO0125175 1 705.60 705.60\n",
      "1 340-11033 NeoNatalie Spare Dk 902300 | TN200259 | SO0125175 15 51.00 765.00\n",
      "1 340-11133 NeoNatalie Spare Lt 902300 | TN200259 | S0125175 3 51.00 153.00\n",
      "1 340-12033 NeoNatalie body (Qt2) Dk 902300 | TN200259 | SO0125175 36.60 36.60\n",
      "38 360-00133 MamaBirthie (light) 902300 | TN200259 | SO0125175 38 586.00 22268.00\n",
      "8 450-00033 LM Mama-U 902300 | TN200259 | SO0125175 36 153.00 5508.00\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "print(pytesseract.image_to_string(Image.open('image.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pytesseract.image_to_data(Image.open('image.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pytesseract.image_to_boxes(Image.open('image.png')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the coordinates of the characters are shown there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay, pytesseract did the job right but it works better when the image is preprocessed,ie clean, high contrast image, so let's use openCV for image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO Item No Description Hscode P/O# S/O# Q'ty(Pcs) Unit Price(USD) Amount(USD)\n",
      "2\n",
      "\n",
      "104-10001 NeoNatalie Basic (dark) 902300 TN200259 | SO125175 20 124.00 2480.00\n",
      "io 340-00333 MamaNatalie Compl Light 902300 TN200259 | SO0125175 10 450.00 4500.00\n",
      "1 340-00533 MamaN Compl (LT) Mama-U 902300 TN200259 | SO125175 a 705.60 705.60\n",
      "1 340-11033 NeoNatalie Spare Dk 902300 TN200259 | SO0125175 a5 51.00 765.00\n",
      "1 340-11133 NeoNatalie Spare Lt 902300 TN200259 | SO125175 3 51.00 153.00\n",
      "1 340-12033 NeoNatalie body (Qt2) Dk 902300 TN200259 | SO0125175 1 36.60 36.60\n",
      "38 360-00133 MamaBirthie (light) 902300 TN200259 | SO125175 38 586.00 22268.00\n",
      "8 450-00033 LM Mama-U 902300 TN200259 | SO0125175 36 153.00 5508.00\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "image_path = \"image.png\"\n",
    "image = cv2.imread(image_path)\n",
    "# print(image)\n",
    "\n",
    "# convert to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# threshold is applied to make the important portion of the image to be prioritized\n",
    "# _, thresh_image = cv2.threshold(gray_image, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "thresh_image = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                     cv2.THRESH_BINARY, 11, 2)\n",
    "                                     \n",
    "\n",
    "# optional step, just to check how image becomes\n",
    "cv2.imwrite(\"text_detection.png\", thresh_image)\n",
    "\n",
    "# pytesseract only works with RGB image so let's convert\n",
    "pil_image = Image.fromarray(cv2.cvtColor(thresh_image, cv2.COLOR_GRAY2RGB))\n",
    "\n",
    "text = pytesseract.image_to_string(pil_image)\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's save this output in a file for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"raw_text.txt\", \"w\") as file:\n",
    "    file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we need to detect the table in the raw text, so that we can disect data as headers and ......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's preprocess the image, now to detect the table, lines and ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "image_path = \"image.png\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                               cv2.THRESH_BINARY_INV, 15, 2)\n",
    "\n",
    "horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 1))  # (Width, Height)\n",
    "thresh_image = cv2.morphologyEx(thresh_image, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)\n",
    "\n",
    "# just for checking image \n",
    "cv2.imwrite(\"lines_detection.png\", thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detecting lines in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = cv2.Canny(thresh, 50, 150, apertureSize=3)\n",
    "\n",
    "# Detect lines using Hough Transform\n",
    "# lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=20, \n",
    "#                         minLineLength=265, maxLineGap=10)\n",
    "\n",
    "\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=155, \n",
    "                        minLineLength=261, maxLineGap=14)\n",
    "\n",
    "# print(lines)\n",
    "image_with_lines = image.copy()\n",
    "\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(image_with_lines, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "\n",
    "cv2.imwrite(\"lines_detected.png\",image_with_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(lines)\n",
    "# image_with_lines = image.copy()\n",
    "\n",
    "# for line in lines:\n",
    "#     x1, y1, x2, y2 = line[0]\n",
    "#     cv2.line(image_with_lines, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv2.imwrite(\"lines_detected.png\",image_with_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now that lines are detected, we need to separate vertical and horizotal lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1  164 1979  164]]\n"
     ]
    }
   ],
   "source": [
    "print(lines[0])\n",
    "# a bit confused which line's cordinate are these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 21 horizontal lines and 12 vertical lines\n"
     ]
    }
   ],
   "source": [
    "# we have values in lines\n",
    "\n",
    "# horizontal_lines = []\n",
    "# vertical_lines = []\n",
    "\n",
    "# for line in lines:\n",
    "#     x1, y1, x2, y2 = line[0]\n",
    "\n",
    "#     # Horizontal lines have a small y-difference (close to 0 slope)\n",
    "#     if abs(y2 - y1) < 10:  # Threshold for horizontal\n",
    "#         horizontal_lines.append([x1, y1, x2, y2])\n",
    "\n",
    "#     # Vertical lines have a small x-difference (close to infinite slope)\n",
    "#     elif abs(x2 - x1) < 10:  # Threshold for vertical\n",
    "#         vertical_lines.append([x1, y1, x2, y2])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "horizontal_lines = []\n",
    "vertical_lines = []\n",
    "\n",
    "line_threshold = 10  # Distance threshold for merging lines\n",
    "min_line_length = 50  # Filter out very short lines\n",
    "\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "\n",
    "    # Horizontal lines detection\n",
    "    if abs(y2 - y1) < 10:  # Close to 0 slope\n",
    "        if abs(x2 - x1) > min_line_length:  # Ignore small lines\n",
    "            horizontal_lines.append([x1, y1, x2, y2])\n",
    "\n",
    "    # Vertical lines detection\n",
    "    elif abs(x2 - x1) < 10:  # Close to infinite slope\n",
    "        if abs(y2 - y1) > min_line_length:  # Ignore small lines\n",
    "            vertical_lines.append([x1, y1, x2, y2])\n",
    "\n",
    "    # Sort lines\n",
    "horizontal_lines = sorted(horizontal_lines, key=lambda x: x[1])  # Sort by y-coordinate\n",
    "vertical_lines = sorted(vertical_lines, key=lambda x: x[0])  # Sort by x-coordinate\n",
    "\n",
    "print(f\"Detected {len(horizontal_lines)} horizontal lines and {len(vertical_lines)} vertical lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int32(2), np.int32(0), np.int32(1980), np.int32(0)]\n"
     ]
    }
   ],
   "source": [
    "print(horizontal_lines[0])\n",
    "# (2,0) (1980,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cells = []\n",
    "for i in range(len(horizontal_lines) - 1):  # Iterate over rows\n",
    "    for j in range(len(vertical_lines) - 1):  # Iterate over columns\n",
    "        x1 = vertical_lines[j][0]  # Left x-coordinate\n",
    "        y1 = horizontal_lines[i][1]  # Top y-coordinate\n",
    "        x2 = vertical_lines[j + 1][0]  # Right x-coordinate\n",
    "        y2 = horizontal_lines[i + 1][1]  # Bottom y-coordinate\n",
    "        cells.append((x1, y1, x2, y2))\n",
    "\n",
    "# Draw the cells on the image for visualization\n",
    "image_with_cells = image.copy()\n",
    "for (x1, y1, x2, y2) in cells:\n",
    "    cv2.rectangle(image_with_cells, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "cv2.imwrite(\"cells_detected.png\", image_with_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we detected the text in the very beginning, but then why are we doing these steps again??\n",
    "well, that was a random text block, but we need the the text along with the cell information\n",
    ",,, in which cell the data is so that we can form the json format according to that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_text = []\n",
    "for idx, (x1, y1, x2, y2) in enumerate(cells):\n",
    "    # Crop the cell from the original image\n",
    "    cell_image = image[y1:y2, x1:x2]\n",
    "    \n",
    "    # Convert to RGB for PIL (pytesseract requires RGB)\n",
    "    cell_image_rgb = cv2.cvtColor(cell_image, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = Image.fromarray(cell_image_rgb)\n",
    "    \n",
    "    # Extract text using pytesseract\n",
    "    text = pytesseract.image_to_string(pil_image).strip()\n",
    "    \n",
    "    # Store the text and coordinates\n",
    "    cell_text.append({\"text\": text, \"coords\": (x1, y1, x2, y2)})\n",
    "    # print(f\"Cell {idx + 1} Text: '{text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open(\"cell_text.json\", \"w\") as f:\n",
    "#     json.dump(cell_text, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer-vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
