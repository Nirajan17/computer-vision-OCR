{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesseract learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO. Item No Description Hscode P/O# S/O# Q'ty(Pcs) Unit Price(USD) Amount(USD)\n",
      "2 104-10001 NeoNatalie Basic (dark) 902300 | TN200259 | S0125175 20 124.00 2480.00\n",
      "10 340-00333 MamaNatalie Compl Light 902300 | TN200259 | S0125175 10 450.00 4500.00\n",
      "1 340-00533 MamaN Compl (LT) Mama-U 902300 | TN200259 | SO0125175 1 705.60 705.60\n",
      "1 340-11033 NeoNatalie Spare Dk 902300 | TN200259 | SO0125175 15 51.00 765.00\n",
      "1 340-11133 NeoNatalie Spare Lt 902300 | TN200259 | S0125175 3 51.00 153.00\n",
      "1 340-12033 NeoNatalie body (Qt2) Dk 902300 | TN200259 | SO0125175 36.60 36.60\n",
      "38 360-00133 MamaBirthie (light) 902300 | TN200259 | SO0125175 38 586.00 22268.00\n",
      "8 450-00033 LM Mama-U 902300 | TN200259 | SO0125175 36 153.00 5508.00\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "print(pytesseract.image_to_string(Image.open('image.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pytesseract.image_to_data(Image.open('image.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pytesseract.image_to_boxes(Image.open('image.png')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the coordinates of the characters are shown there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay, pytesseract did the job right but it works better when the image is preprocessed,ie clean, high contrast image, so let's use openCV for image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "image_path = \"image.png\"\n",
    "image = cv2.imread(image_path)\n",
    "# print(image)\n",
    "\n",
    "# convert to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# threshold is applied to make the important portion of the image to be prioritized\n",
    "# _, thresh_image = cv2.threshold(gray_image, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "thresh_image = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                     cv2.THRESH_BINARY, 11, 2)\n",
    "                                     \n",
    "\n",
    "# optional step, just to check how image becomes\n",
    "cv2.imwrite(\"text_detection.png\", thresh_image)\n",
    "\n",
    "# pytesseract only works with RGB image so let's convert\n",
    "pil_image = Image.fromarray(cv2.cvtColor(thresh_image, cv2.COLOR_GRAY2RGB))\n",
    "\n",
    "text = pytesseract.image_to_string(pil_image)\n",
    "\n",
    "# print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's save this output in a file for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"raw_text.txt\", \"w\") as file:\n",
    "    file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we need to detect the table in the raw text, so that we can disect data as headers and ......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's preprocess the image, now to detect the table, lines and ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "image_path = \"image.png\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                               cv2.THRESH_BINARY_INV, 15, 2)\n",
    "\n",
    "horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 1))  # (Width, Height)\n",
    "thresh_image = cv2.morphologyEx(thresh_image, cv2.MORPH_OPEN, horizontal_kernel, iterations=5)\n",
    "\n",
    "# just for checking image \n",
    "cv2.imwrite(\"lines_detection.png\", thresh_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                               cv2.THRESH_BINARY_INV, 15, 2)\n",
    "# Thin the lines with erosion\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "# Morphological operation to enhance horizontal lines\n",
    "horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))\n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel, iterations=8)  # Reduced iterations\n",
    "cv2.imwrite(\"lines_detection.png\", thresh)  # Check this output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # this code !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizontal lines: 11, Vertical lines: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image_path = \"image.png\"\n",
    "image = cv2.imread(image_path)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Adaptive thresholding\n",
    "thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                               cv2.THRESH_BINARY_INV, 15, 2)\n",
    "\n",
    "horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (60, 1))  # Narrower kernel\n",
    "thresh_horizontal = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel, iterations=1)  # Fewer iterations\n",
    "# cv2.imwrite(\"horizontal_thresh.png\", thresh_horizontal)\n",
    "\n",
    "edges_horizontal = cv2.Canny(thresh_horizontal, 100, 200, apertureSize=3)  # Higher Canny thresholds\n",
    "# cv2.imwrite(\"edges_horizontal.png\", edges_horizontal)  # Debug\n",
    "\n",
    "lines_horizontal = cv2.HoughLinesP(edges_horizontal, 1, np.pi / 180, \n",
    "                                   threshold=400,  # Higher threshold\n",
    "                                   minLineLength=350,  # Longer minimum length\n",
    "                                   maxLineGap=100)  # Smaller gap tolerance\n",
    "\n",
    "\n",
    "# merging two close horizontal lines\n",
    "def merge_close_horizontal_lines(lines, distance_threshold=20):\n",
    "    if lines is None or len(lines) == 0:\n",
    "        return []\n",
    "    # Extract lines and sort by y-coordinate\n",
    "    lines_list = [line[0] for line in lines]\n",
    "    lines_list = sorted(lines_list, key=lambda x: x[1])  # Sort by y1\n",
    "    \n",
    "    merged = []\n",
    "    current = lines_list[0]\n",
    "    for line in lines_list[1:]:\n",
    "        x1, y1, x2, y2 = line\n",
    "        cx1, cy1, cx2, cy2 = current\n",
    "        # Check if lines are close in y and overlap or are close in x\n",
    "        if abs(y1 - cy1) < distance_threshold:\n",
    "            # Check if they overlap in x or have a small gap\n",
    "            if (x1 <= cx2 and x2 >= cx1) or abs(x1 - cx2) < 100 + 20:\n",
    "                # Merge by taking the widest x-range\n",
    "                current = [min(cx1, x1), cy1, max(cx2, x2), cy2]\n",
    "            else:\n",
    "                merged.append(current)\n",
    "                current = [x1, y1, x2, y2]\n",
    "        else:\n",
    "            merged.append(current)\n",
    "            current = [x1, y1, x2, y2]\n",
    "    merged.append(current)\n",
    "    return merged\n",
    "\n",
    "# Apply merging\n",
    "merged_horizontal_lines = merge_close_horizontal_lines(lines_horizontal, distance_threshold=200)\n",
    "\n",
    "lines_horizontal = lines_horizontal\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 50))  # Taller kernel\n",
    "thresh_vertical = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel, iterations=1)  # Fewer iterations\n",
    "# cv2.imwrite(\"vertical_thresh.png\", thresh_vertical)\n",
    "edges_vertical = cv2.Canny(thresh_vertical, 50, 150, apertureSize=3)\n",
    "# cv2.imwrite(\"edges_vertical.png\", edges_vertical)  # Debug edges\n",
    "lines_vertical = cv2.HoughLinesP(edges_vertical, 1, np.pi / 180, threshold=100,  # Lower threshold\n",
    "                                 minLineLength=200, maxLineGap=30)\n",
    "\n",
    "# Combine and classify\n",
    "horizontal_lines = []\n",
    "vertical_lines = []\n",
    "min_line_length = 50\n",
    "\n",
    "# Horizontal lines from horizontal processing\n",
    "if lines_horizontal is not None:\n",
    "    for line in lines_horizontal:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        if abs(y2 - y1) < 20 and abs(x2 - x1) > min_line_length:\n",
    "            horizontal_lines.append([x1, y1, x2, y2])\n",
    "\n",
    "# Vertical lines from vertical processing\n",
    "if lines_vertical is not None:\n",
    "    for line in lines_vertical:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        if abs(x2 - x1) < 20 and abs(y2 - y1) > min_line_length:\n",
    "            vertical_lines.append([x1, y1, x2, y2])\n",
    "\n",
    "print(f\"Horizontal lines: {len(horizontal_lines)}, Vertical lines: {len(vertical_lines)}\")\n",
    "\n",
    "# Visualize\n",
    "image_with_lines = image.copy()\n",
    "for line in horizontal_lines:\n",
    "    x1, y1, x2, y2 = line\n",
    "    cv2.line(image_with_lines, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "for line in vertical_lines:\n",
    "    x1, y1, x2, y2 = line\n",
    "    cv2.line(image_with_lines, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "cv2.imwrite(\"lines_detected.png\", image_with_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# above!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detecting lines in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# edges = cv2.Canny(thresh, 50, 150, apertureSize=3)\n",
    "\n",
    "# # Detect lines using Hough Transform\n",
    "# # lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=20, \n",
    "# #                         minLineLength=265, maxLineGap=10)\n",
    "\n",
    "\n",
    "# lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=155, \n",
    "#                         minLineLength=261, maxLineGap=100)\n",
    "\n",
    "# lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=200, \n",
    "#                         minLineLength=300, maxLineGap=20)\n",
    "\n",
    "# # print(lines)\n",
    "# image_with_lines = image.copy()\n",
    "\n",
    "# for line in lines:\n",
    "#     x1, y1, x2, y2 = line[0]\n",
    "#     cv2.line(image_with_lines, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "\n",
    "# cv2.imwrite(\"lines_detected.png\",image_with_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now that lines are detected, we need to separate vertical and horizotal lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort lines for consistent cell boundaries\n",
    "horizontal_lines = sorted(horizontal_lines, key=lambda x: x[1])  # Sort by y-coordinate\n",
    "vertical_lines = sorted(vertical_lines, key=lambda x: x[0])    # Sort by x-coordinate\n",
    "\n",
    "# Detect cells\n",
    "cells = []\n",
    "for i in range(len(horizontal_lines) - 1):  # Iterate over rows\n",
    "    for j in range(len(vertical_lines) - 1):  # Iterate over columns\n",
    "        # Define cell boundaries\n",
    "        x1 = vertical_lines[j][0]      # Left x-coordinate (from vertical line)\n",
    "        y1 = horizontal_lines[i][1]    # Top y-coordinate (from horizontal line)\n",
    "        x2 = vertical_lines[j + 1][0]  # Right x-coordinate (next vertical line)\n",
    "        y2 = horizontal_lines[i + 1][1] # Bottom y-coordinate (next horizontal line)\n",
    "        cells.append((x1, y1, x2, y2))\n",
    "\n",
    "# Optional: Visualize cells on the image\n",
    "image_with_cells = image.copy()\n",
    "for (x1, y1, x2, y2) in cells:\n",
    "    cv2.rectangle(image_with_cells, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red rectangles\n",
    "cv2.imwrite(\"cells_detected.png\", image_with_cells)\n",
    "\n",
    "# print(f\"Detected {len(cells)} cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we detected the text in the very beginning, but then why are we doing these steps again??\n",
    "well, that was a random text block, but we need the the text along with the cell information\n",
    ",,, in which cell the data is so that we can form the json format according to that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_text = []\n",
    "for idx, (x1, y1, x2, y2) in enumerate(cells):\n",
    "    # Crop the cell from the original image\n",
    "    cell_image = image[y1:y2, x1:x2]\n",
    "    \n",
    "    # Convert to RGB for PIL (pytesseract requires RGB)\n",
    "    cell_image_rgb = cv2.cvtColor(cell_image, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = Image.fromarray(cell_image_rgb)\n",
    "    \n",
    "    # Extract text using pytesseract\n",
    "    text = pytesseract.image_to_string(pil_image).strip()\n",
    "    \n",
    "    # Store the text and coordinates\n",
    "    cell_text.append({\"text\": text, \"coords\": (x1, y1, x2, y2)})\n",
    "    # print(f\"Cell {idx + 1} Text: '{text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'NO.', 'coords': (np.int32(1), np.int32(0), np.int32(84), np.int32(26))}\n",
      "{'text': 'Item No', 'coords': (np.int32(84), np.int32(0), np.int32(282), np.int32(26))}\n",
      "{'text': 'Description', 'coords': (np.int32(282), np.int32(0), np.int32(950), np.int32(26))}\n",
      "{'text': 'Hscode', 'coords': (np.int32(950), np.int32(0), np.int32(1070), np.int32(26))}\n",
      "{'text': 'P/O#', 'coords': (np.int32(1070), np.int32(0), np.int32(1215), np.int32(26))}\n",
      "{'text': 'S/O#', 'coords': (np.int32(1215), np.int32(0), np.int32(1355), np.int32(26))}\n",
      "{'text': \"O'ty(Pcs)\", 'coords': (np.int32(1355), np.int32(0), np.int32(1505), np.int32(26))}\n",
      "{'text': 'Unit Price(USD)', 'coords': (np.int32(1505), np.int32(0), np.int32(1763), np.int32(26))}\n",
      "{'text': 'Amount(USD)', 'coords': (np.int32(1763), np.int32(0), np.int32(1979), np.int32(26))}\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(cell_text[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "upto 9, we have our header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_text = sorted(cell_text, key=lambda x: x[\"coords\"][1])  # Sort by y1\n",
    "\n",
    "headers_raw = [cell[\"text\"] for cell in cell_text[:9]]  # First 9 cells = header row\n",
    "data_cells = cell_text[9:]  # Remaining cells = data rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NO.', 'Item No', 'Description', 'Hscode', 'P/O#', 'S/O#', \"O'ty(Pcs)\", 'Unit Price(USD)', 'Amount(USD)']\n"
     ]
    }
   ],
   "source": [
    "print(headers_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i will see later from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open(\"cell_text.json\", \"w\") as f:\n",
    "#     json.dump(cell_text, f)\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def default_converter(o):\n",
    "    if isinstance(o, np.integer):\n",
    "        return int(o)\n",
    "    raise TypeError(f\"Object {o} is not JSON serializable\")\n",
    "\n",
    "with open(\"cell_text.json\", \"w\") as f:\n",
    "    json.dump(cell_text, f, default=default_converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Headers: ['no', 'item_no', 'description', 'hscode', 'p_o', 's_o', 'o_ty_pcs', 'unit_price_usd', 'amount_usd']\n"
     ]
    }
   ],
   "source": [
    "# Assume cell_text is already populated from the previous step\n",
    "headers_raw = [cell[\"text\"] for cell in cell_text[:9]]  # First row (8 cells)\n",
    "\n",
    "# Process each header: lowercase, underscore-separated, remove non-alphabet\n",
    "import re\n",
    "headers = []\n",
    "for header in headers_raw:\n",
    "    # Convert to lowercase and replace non-alphabet with underscore\n",
    "    processed = re.sub(r'[^a-z0-9]+', '_', header.lower()).strip('_')\n",
    "    headers.append(processed if processed else \"unknown\")  # Avoid empty strings\n",
    "\n",
    "print(\"Processed Headers:\", headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows detected: 9\n",
      "Row 1: ['', '', '', '', '', '', '', '', '']\n",
      "Row 2: ['', '104-10001', 'NeoNatalie Basic (dark)', '902300', 'TN200259', '$0125175', '20', '124.00', '2480.00']\n",
      "Row 3: ['', '340-00333', 'MamaNatalie Comp! Light', '902300', 'TN200259', '$0125175', '', '450.00', '4500.00']\n",
      "Row 4: ['', '340-00533', 'MamaN Compl (LT) Mama-U', '902300', 'TN200259', '$0125175', '', '705.60', '705.60']\n",
      "Row 5: ['', '340-11033', 'NeoNatalie Spare Dk', '902300', 'TN200259', '$0125175', '', '', '765.00']\n",
      "Row 6: ['', '340-11133', 'NeoNatalie Spare Lt', '902300', 'TN200259', '$0125175', '', '', '153.00']\n",
      "Row 7: ['', '340-12033', 'NeoNatalie body (Qt2) Dk', '902300', 'TN200259', '$0125175', '', '', '36.60']\n",
      "Row 8: ['', '360-00133', 'MamaBirthie (light)', '902300', 'TN200259', '$0125175', '', '586.00', '22268.00']\n",
      "Row 9: ['', '450-00033', 'LM Mama-U', '902300', 'TN200259', '$0125175', '', '153.00', '5508.00']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_cells = cell_text[9:]  # Exclude header row\n",
    "rows = [data_cells[i:i + 9] for i in range(0, len(data_cells), 9)]\n",
    "\n",
    "print(f\"Total rows detected: {len(rows)}\")\n",
    "for idx, row in enumerate(rows):\n",
    "    print(f\"Row {idx + 1}: {[cell['text'] for cell in row]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Data: [{'no': '', 'item_no': '', 'description': '', 'hscode': '', 'p_o': '', 's_o': '', 'o_ty_pcs': '', 'unit_price_usd': '', 'amount_usd': ''}, {'no': '', 'item_no': '104-10001', 'description': 'NeoNatalie Basic (dark)', 'hscode': '902300', 'p_o': 'TN200259', 's_o': '$0125175', 'o_ty_pcs': '20', 'unit_price_usd': '124.00', 'amount_usd': '2480.00'}, {'no': '', 'item_no': '340-00333', 'description': 'MamaNatalie Comp! Light', 'hscode': '902300', 'p_o': 'TN200259', 's_o': '$0125175', 'o_ty_pcs': '', 'unit_price_usd': '450.00', 'amount_usd': '4500.00'}, {'no': '', 'item_no': '340-00533', 'description': 'MamaN Compl (LT) Mama-U', 'hscode': '902300', 'p_o': 'TN200259', 's_o': '$0125175', 'o_ty_pcs': '', 'unit_price_usd': '705.60', 'amount_usd': '705.60'}, {'no': '', 'item_no': '340-11033', 'description': 'NeoNatalie Spare Dk', 'hscode': '902300', 'p_o': 'TN200259', 's_o': '$0125175', 'o_ty_pcs': '', 'unit_price_usd': '', 'amount_usd': '765.00'}, {'no': '', 'item_no': '340-11133', 'description': 'NeoNatalie Spare Lt', 'hscode': '902300', 'p_o': 'TN200259', 's_o': '$0125175', 'o_ty_pcs': '', 'unit_price_usd': '', 'amount_usd': '153.00'}, {'no': '', 'item_no': '340-12033', 'description': 'NeoNatalie body (Qt2) Dk', 'hscode': '902300', 'p_o': 'TN200259', 's_o': '$0125175', 'o_ty_pcs': '', 'unit_price_usd': '', 'amount_usd': '36.60'}, {'no': '', 'item_no': '360-00133', 'description': 'MamaBirthie (light)', 'hscode': '902300', 'p_o': 'TN200259', 's_o': '$0125175', 'o_ty_pcs': '', 'unit_price_usd': '586.00', 'amount_usd': '22268.00'}, {'no': '', 'item_no': '450-00033', 'description': 'LM Mama-U', 'hscode': '902300', 'p_o': 'TN200259', 's_o': '$0125175', 'o_ty_pcs': '', 'unit_price_usd': '153.00', 'amount_usd': '5508.00'}]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of dictionaries\n",
    "json_data = []\n",
    "for row in rows:\n",
    "    row_dict = {}\n",
    "    for header, cell in zip(headers, [cell[\"text\"] for cell in row]):\n",
    "        row_dict[header] = cell\n",
    "    json_data.append(row_dict)\n",
    "\n",
    "print(\"JSON Data:\", json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file saved as 'output.json'\n"
     ]
    }
   ],
   "source": [
    "# Save to JSON file\n",
    "with open(\"output.json\", \"w\") as f:\n",
    "    json.dump(json_data, f, indent=4)\n",
    "\n",
    "print(\"JSON file saved as 'output.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission zip file created as 'submission.zip'\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Create a zip file\n",
    "with zipfile.ZipFile(\"submission.zip\", \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipf.write(\"output.json\")\n",
    "    zipf.write(\"image.png\")\n",
    "\n",
    "print(\"Submission zip file created as 'submission.zip'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer-vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
